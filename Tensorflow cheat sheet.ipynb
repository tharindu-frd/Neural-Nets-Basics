{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b907f7e8-8719-451c-a755-1a9824b8fcd4",
   "metadata": {},
   "source": [
    "# Tensorflow cheat sheet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4a7a76-b256-40c3-9718-3af579bad2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa73d8a-bec8-49c3-b5d4-8e997113312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the tf version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e305dd-c144-4995-98f0-ac23ed7071d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = tf.constant(43)\n",
    "#### Once initialized we cant change the values of the constants \n",
    "constant_matrix = tf.constant([[1,2,3],[4,5,6]])  # constant_matrix = tf.constant([[1,2,3],[4,5,6]],dtype=tf.float32)\n",
    "constant_matrix.shape\n",
    "constant_matrix[0][0]\n",
    "\n",
    "tf.ones(shape=(2,3))  # -1*tf.ones(shape=(2,3))  : multiply all the items by -1\n",
    "tf.zeros(shape=(2,3))  ###  We can use these as placeholders to store weights \n",
    "\n",
    "tf.random.normal(shape=(2,2) , mean=0 , stddev=1.0)\n",
    "tf.random.uniform(shape=(2,2) , minval=0 , maxval=20)\n",
    "\n",
    "\n",
    "tf_var = tf.Variable([[2,3,4],[5,6,7]])  ## Here we cant change the values => tf_var[0,0].assign(100)\n",
    "tf.Variable(43)\n",
    "tensor = tf.Variable([[[10, 11, 12], [13, 15, 18]],[[10, 11, 12], [13, 15, 18]]])\n",
    "tensor \n",
    "'''\n",
    "output :\n",
    "array([[[10, 11, 12],\n",
    "        [13, 15, 18]],\n",
    "\n",
    "       [[10, 11, 12],\n",
    "        [13, 15, 18]]])>\n",
    "\n",
    "'''\n",
    "\n",
    "tensor[0,:,1:] \n",
    "'''\n",
    "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
    "array([[11, 12],\n",
    "       [15, 18]])>\n",
    "\n",
    "'''\n",
    "\n",
    "################   Reshaping\n",
    "tensor = tf.Variable([[22,2,3],[4,5,6]])\n",
    "tensor.shape\n",
    "tf.reshape(tensor,[3,2])  ## Transpose\n",
    "tf.reshape(tensor ,[6,1])\n",
    "\n",
    "########## squared the values \n",
    "# tf.square(var1)\n",
    "\n",
    "\n",
    "########## Rank of tensors (no of dimensions ) \n",
    "tensor = tf.Variable([[22,2,3],[4,5,6]])\n",
    "tf.rank(tensor)  # output :  <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
    "\n",
    "\n",
    "######## Basic Operations \n",
    "const1 = tf.constant([[1,2,3],[4,5,6]],dtype=tf.float32)\n",
    "const2 = tf.constant([[2,4,5],[9,8,2]],dtype=tf.float32)\n",
    "tf.add(const1,const2)\n",
    "tf.square(const1)\n",
    "tf.exp(const1)\n",
    "const1*const2  ## Element wise multiplication\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "##########################   Broadcasting #######################################\n",
    "################################################################################\n",
    "scalar = 4\n",
    "scalar*tensor\n",
    "scalar+tensor\n",
    "scalar-tensor\n",
    "\n",
    "\n",
    "################################################################################\n",
    "##########################  Matrix multiplication  #############################\n",
    "################################################################################\n",
    "mat_u = tf.constant([[6,7,7]])\n",
    "mat_v = tf.constant([[3,4,3]])\n",
    "tf.transpose(mat_u)\n",
    "mat_u.numpy()  # to convert to an numpy array\n",
    "tf.matmul(mat_u , tf.transpose(mat_v))\n",
    "tf.matmul(tf.transpose(mat_v), mat_u)\n",
    "tf.transpose(mat_v) @ mat_u ### <<< Matrix mul\n",
    "mat_u @ tf.transpose(mat_v) ### <<< Matrix mul\n",
    "mat_u * mat_v # element wise multiplication\n",
    "\n",
    "\n",
    "varx = [1,2,3,4,5,6]\n",
    "vary = 2\n",
    "tf.math.squared_difference(varx,vary)   ######### Squared difference \n",
    "\n",
    "num = tf.constant([[1,2] , [3,4]])\n",
    "tf.reduce_mean(num) ## total mean\n",
    "tf.reduce_mean(num , axis=1)\n",
    "tf.reduce_mean(num , axis=0)\n",
    "tf.reduce_max(num)\n",
    "tf.reduce_min(num)\n",
    "tf.reduce_sum(num)\n",
    "tf.reduce_prod(num)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "################  Ragged tensors (nested arrays with varying lengths ) ####\n",
    "###########################################################################\n",
    "ragged = tf.ragged.constant([[1,2,3,4,5],[1],[135,1]])\n",
    "ragged[0]\n",
    "ragged[1]\n",
    "ragged[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f471843-bb22-42b9-987a-e38b31697a0e",
   "metadata": {},
   "source": [
    "#  CheckPointing ( restore matrix values ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d145e658-e8d3-4eec-99fa-812f74e7ab7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5, 5) dtype=float32, numpy=\n",
       "array([[5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = tf.Variable(5*tf.ones((5,5)))\n",
    "ckpt = tf.train.Checkpoint(var=var1)\n",
    "savepath = ckpt.save('vars.ckpt')\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "217d1aff-8d2e-4e15-82a1-28f20aa33e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5, 5) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1.assign(tf.zeros((5,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29395ddd-477a-4171-85b8-58762b66a5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x235919a13d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.restore(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dcb1b09-382f-4ee3-830b-f3b7cfc79ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5, 5) dtype=float32, numpy=\n",
       "array([[5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.],\n",
       "       [5., 5., 5., 5., 5.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ed4f8-8af5-4e36-8e6b-ed368da1ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5763ea7-4fec-4432-a59f-7f9be926b523",
   "metadata": {},
   "source": [
    "# Tensorflow functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f96fc8-f25e-4ba1-8476-10cad1a1a636",
   "metadata": {},
   "source": [
    "$ z = (x^3)*6 + y^3 $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1cf5785-bb25-4dbc-821c-4926da573d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-78.5>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function  ## tf decorator function\n",
    "def f2(x,y):\n",
    "    input_var = tf.multiply(x**3,6) + y**3\n",
    "    return tf.reduce_mean(input_tensor = input_var)\n",
    "## Decorator is a more of a like wrapper and it provides more functionalities to the function without \n",
    "## changing the definition\n",
    "\n",
    "x = tf.constant([3.,-4.])\n",
    "y = tf.constant([1.,4.])\n",
    "f2(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4197186-dcd3-462a-9475-b31caea7b830",
   "metadata": {},
   "source": [
    "# Slicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0bc000-e7b5-4444-87a8-429beb9af3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29201f-ccc9-4d90-99c3-c74daf292651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b5ad2a-e4db-4e14-964d-fb4cc1bf8cb4",
   "metadata": {},
   "source": [
    "# Gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df2423-86f7-4858-9f37-9736f238be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal(shape=(2,2))\n",
    "y = tf.random.normal(shape=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b996d4c2-052b-45fa-9c71-7c9c87966bf8",
   "metadata": {},
   "source": [
    "$ f(x,y) = \\sqrt{x^2 + y^2 } $\n",
    "<br>\n",
    "$\\nabla f(x,y) = \\frac{\\partial f}{\\partial x}\\hat{\\imath} + \\frac{\\partial f}{\\partial y}\\hat{\\jmath}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdfac5-3e68-4aee-9bdf-b4499833a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Partial derivative of f with respect to x \n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x) ### <<< I want to calculate grad wrt x\n",
    "  f = tf.sqrt(tf.square(x) + tf.square(y))\n",
    "\n",
    "  df_dx = tape.gradient(f, x)   #  partial derivative of f with respect to x \n",
    "\n",
    "  print(df_dx)\n",
    "\n",
    "\n",
    "\n",
    "#### partial derivative of f with respect to y \n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(y) ### <<< I want to calculate grad wrt y\n",
    "  f = tf.sqrt(tf.square(x) + tf.square(y))\n",
    "\n",
    "  df_dy = tape.gradient(f, y)  #  partial derivative of f with respect to y\n",
    "\n",
    "  print(df_dy)\n",
    "\n",
    "\n",
    "\n",
    "######## Get both the partial derivatives at once \n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(y) ### <<< I want to calculate grad wrt y\n",
    "  tape.watch(x) ### <<< I want to calculate grad wrt x\n",
    "  f = tf.sqrt(tf.square(x) + tf.square(y))\n",
    "\n",
    "  df_dx, df_dy = tape.gradient(f, [x, y]) \n",
    "    ## partial diff wrt x and y  , we can use this to find the gradient \n",
    "\n",
    "  print(df_dx)\n",
    "  print(df_dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "651ed0de-8ca2-4caf-99b6-ed58a0b1f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.8190673   0.22711253]\n",
      " [-0.9788309  -0.9413712 ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.57369745  0.9738686 ]\n",
      " [-0.20467056  0.33737263]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## tf.watch is only needed when X and Y are not variables.Because we have defined x and y using \n",
    "# tf.random.normal(shape=(2,2))  and it creates a constant . If we define the x and y in the following way\n",
    "# we dont have to use tape.watch()\n",
    "x= tf.Variable(tf.random.normal(shape=(2,2)))\n",
    "y = tf.Variable(tf.random.normal(shape=(2,2)))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  f = tf.sqrt(tf.square(x) + tf.square(y))\n",
    "\n",
    "  df_dx, df_dy = tape.gradient(f, [x, y]) ## partial diff wrt x and y\n",
    "\n",
    "  print(df_dx)\n",
    "  print(df_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e183471-55c4-4c02-80cc-3b64cace8eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.8190673 ,  0.22711253],\n",
       "       [-0.97883093, -0.9413712 ]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x/tf.sqrt(tf.square(x) + tf.square(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58eca605-a94c-49b0-b785-8b0f10640f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 0.57369745,  0.97386855],\n",
       "       [-0.20467058,  0.33737263]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y/tf.sqrt(tf.square(x) + tf.square(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d76fc2-8cf2-4585-9244-aacd992606e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5329f75e-8c61-4c7c-991e-0ce98c82e71d",
   "metadata": {},
   "source": [
    "## Jarcobians "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c9b0ca6-8d5f-4d89-96e0-0dae531cdfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tf.Tensor([-10.  -5.   0.   5.  10.], shape=(5,), dtype=float32)\n",
      "y : tf.Tensor([4.539787e-05 6.692851e-03 5.000000e-01 9.933072e-01 9.999546e-01], shape=(5,), dtype=float32)\n",
      "tf.Tensor([4.5395806e-05 6.6480567e-03 2.5000000e-01 6.6480329e-03 4.5416677e-05], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.linspace(-10.0, 10.0, 5)\n",
    "print('x :' , x )\n",
    "delta = tf.Variable(0.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = tf.nn.sigmoid(x+delta)    ##  This is our function . As earlier we used f here we use y to define our function \n",
    "  print('y :' , y)\n",
    "    \n",
    "dy_dx = tape.jacobian(y, delta)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bea9b4-bab7-4829-aa9a-0731e16ba747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5d7a86c-28d7-43bc-95bc-5ced32894ed6",
   "metadata": {},
   "source": [
    "# Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c2ce0-f498-4e2d-96ba-7f7e5165b553",
   "metadata": {},
   "source": [
    "$ f(x) = W.x + b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd07a2-eeac-4f5f-bb4c-9a0483ddb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######  First lets create a data set \n",
    "TRUE_W = 3.0   # weights \n",
    "TRUE_B = 2.0   # bias \n",
    "## those are the exact answers for weights and bias \n",
    "\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "x = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "y = x * TRUE_W + TRUE_B + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da911e-ed34-4acb-83c2-47ad43a79f42",
   "metadata": {},
   "source": [
    "* In Python, super() is a function that provides a way to access methods and properties from a parent or superclass within a subclass. It's commonly used in object-oriented programming (OOP) to call methods of the parent class in cases where the subclass overrides those methods. \n",
    "* Accessing Parent Class Methods: When a method is overridden in a subclass, you might still want to call the parent class's version of the method from within the subclass. super() allows you to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8f866-4658-4367-901c-7b25c9e6324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Parent:\n",
    "    def method(self):\n",
    "        print(\"Parent method\")\n",
    "\n",
    "class Child(Parent):\n",
    "    def method(self):\n",
    "        super().method()  # Calls the method of the parent class\n",
    "        print(\"Child method\")\n",
    "\n",
    "child = Child()\n",
    "child.method()\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49916967-e579-47f1-bc64-5255e2ddd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "\n",
    "    # initial weights\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.w*x + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb1124-7f4b-4f6e-b99c-84de923e19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2caf58-0b60-480a-ac69-be160be9cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########  Lets define a loss function \n",
    "def MSE_loss(target_y, predicted_y):\n",
    "  error = target_y - predicted_y\n",
    "  squared_error = tf.square(error)\n",
    "  mse = tf.reduce_mean(squared_error)\n",
    "  return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a216b8-cead-4682-bcf2-5394f10cf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, learning_rate):\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    current_loss = MSE_loss(y, model(x))\n",
    "\n",
    "  dc_dw, dc_db = tape.gradient(current_loss, [model.w, model.b])\n",
    "\n",
    "  model.w.assign_sub(learning_rate * dc_dw)\n",
    "  #assign_sub is a TensorFlow operation used to update the value of a variable by \n",
    "  # subtracting another tensor from it. It is typically used in scenarios where you want\n",
    "  # to perform in-place subtraction to update the value of a variable.\n",
    "  model.b.assign_sub(learning_rate * dc_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd63e3d-e10d-45ac-bc43-762d6721df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "Ws, bs = [], []\n",
    "\n",
    "epochs = 10*2\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "w = model.w.numpy()\n",
    "b = model.b.numpy()\n",
    "\n",
    "init_loss = MSE_loss(y, model(x)).numpy()\n",
    "\n",
    "print(f\"Initial W: {w}, initial bias: {b}, initial_loss: {init_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a7a4d-c23c-4e6b-800f-5c8240a0496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "  train(model, x, y, learning_rate)\n",
    "\n",
    "  Ws.append(model.w.numpy())\n",
    "  bs.append(model.b.numpy())\n",
    "\n",
    "  current_loss = MSE_loss(y, model(x))\n",
    "\n",
    "  print(f\"For epoch: {epoch}, W: {Ws[-1]}, b: {bs[-1]}, current_loss: {current_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af12bf2-f43a-475c-9cf8-b64d92256775",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), Ws, 'r', range(epochs), bs, \"b\")\n",
    "\n",
    "plt.plot([TRUE_W] * epochs, \"r--\", [TRUE_B] * epochs, \"b--\")\n",
    "\n",
    "plt.legend([\"W\", \"b\", \"True W\", \"True B\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c131c5-101a-48d3-b9aa-da0279f12f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa383884-71ae-4418-a9fa-95fb476dfdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e94cd5-0f09-486f-be9b-5b8aa52261fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d957617-3f0e-469d-9184-e90b1b1ce5f4",
   "metadata": {},
   "source": [
    " # 3 by 3 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc1b505-5c2f-4f26-9319-4db34fc04b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 30,  24,  18],\n",
       "       [ 84,  69,  54],\n",
       "       [138, 114,  90]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example tensors\n",
    "tensor1 = tf.constant([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "tensor2 = tf.constant([[9, 8, 7],\n",
    "                       [6, 5, 4],\n",
    "                       [3, 2, 1]])\n",
    "\n",
    "# Compute dot product\n",
    "dot_product = tf.tensordot(tensor1, tensor2, axes=1)\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941c9fc1-4e95-4e1a-a2a9-91d101235bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################     2D convolution   ##########################################\n",
    "####################################################################################################\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "# Example input tensor (4D tensor: batch_size, height, width, channels)\n",
    "input_tensor = tf.constant([\n",
    "    [\n",
    "        [[1.0], [2.0], [3.0]],\n",
    "        [[4.0], [5.0], [6.0]],\n",
    "        [[7.0], [8.0], [9.0]]\n",
    "    ]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Example filter/kernel tensor (4D tensor: height, width, input_channels, output_channels)\n",
    "filter_tensor = tf.constant([\n",
    "    [\n",
    "        [[1.0]], \n",
    "        [[0.0]], \n",
    "        [[-1.0]]\n",
    "    ],\n",
    "    [\n",
    "        [[1.0]], \n",
    "        [[0.0]], \n",
    "        [[-1.0]]\n",
    "    ],\n",
    "    [\n",
    "        [[1.0]], \n",
    "        [[0.0]], \n",
    "        [[-1.0]]\n",
    "    ]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Perform convolution\n",
    "convolution_result = tf.nn.conv2d(input=input_tensor, filters=filter_tensor, strides=[1, 1, 1, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ccc14e-7a62-4b27-a2e9-93a214c729fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1, 1), dtype=float32, numpy=array([[[[[-6.]]]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################     3D convolution   ##########################################\n",
    "####################################################################################################\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "# Example input tensor (5D tensor: batch_size, depth, height, width, channels)\n",
    "input_tensor = tf.constant([[[[[1.0], [2.0], [3.0]],\n",
    "                              [[4.0], [5.0], [6.0]],\n",
    "                              [[7.0], [8.0], [9.0]]]]], dtype=tf.float32)\n",
    "\n",
    "# Example filter/kernel tensor (5D tensor: depth, height, width, input_channels, output_channels)\n",
    "filter_tensor = tf.constant([[[[[1.0]], \n",
    "                                [[0.0]], \n",
    "                                [[-1.0]]],\n",
    "\n",
    "                               [[[1.0]], \n",
    "                                [[0.0]], \n",
    "                                [[-1.0]]],\n",
    "\n",
    "                               [[[1.0]], \n",
    "                                [[0.0]], \n",
    "                                [[-1.0]]]]], dtype=tf.float32)\n",
    "\n",
    "# Perform 3D convolution\n",
    "convolution_result = tf.nn.conv3d(input=input_tensor, filters=filter_tensor, strides=[1, 1, 1, 1, 1], padding='VALID')\n",
    "convolution_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1af2baf-bae2-49bc-8439-d6beeb5fa088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 2), dtype=float32, numpy=array([[[[7., 8.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################     Pooling   ##########################################\n",
    "####################################################################################################\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "# Example input tensor\n",
    "input_tensor = tf.constant([[[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]]])\n",
    "\n",
    "# Perform max pooling\n",
    "pooled_output = tf.nn.pool(input=input_tensor, window_shape=[2, 2], pooling_type='MAX', padding='VALID', strides=[2, 2])\n",
    "pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab7dc6-cf03-4cdb-8ab7-57c5ab2628a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################     padding    ##########################################\n",
    "####################################################################################################\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "# Example input tensor\n",
    "input_tensor = tf.constant([[[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]]])\n",
    "\n",
    "# Perform max pooling with padding\n",
    "pooled_output = tf.nn.pool(input=input_tensor, window_shape=[2, 2], pooling_type='MAX', padding='SAME', strides=[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e75e8f-366e-490b-ba4f-ebe5a83cfae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################     Dilation   ##########################################\n",
    "####################################################################################################\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "# Example input tensor\n",
    "input_tensor = tf.constant([[[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]]])\n",
    "\n",
    "# Example filter/kernel tensor\n",
    "filter_tensor = tf.constant([[[[1.0]], [[0.0]], [[-1.0]]]])\n",
    "\n",
    "# Perform 2D convolution with dilation\n",
    "convolution_result = tf.nn.conv2d(input=input_tensor, filters=filter_tensor, strides=[1, 1, 1, 1], padding='VALID', dilations=[1, 2, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7524fc5-15c0-4781-9a90-9ed3062921ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7af50-65c9-4525-9574-3b09aae606e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2803f080-dab3-4d16-a102-53e208bd2edd",
   "metadata": {},
   "source": [
    "# Additional "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae392151-0357-4c6e-aac4-980f2dbfe4b6",
   "metadata": {},
   "source": [
    "### Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b4f95-73ae-4d61-984b-ab6a7fbbca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tensor value is <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
    "tf.RaggedTensor.from_row_splits(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8]\n",
    ")\n",
    "\n",
    "# The tensor value is <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
    "tf.RaggedTensor.from_row_lengths(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2, 6], row_lengths=[4, 0, 3, 1, 0]\n",
    ")\n",
    "\n",
    "# The tensor value is <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
    "tf.RaggedTensor.from_value_rowids(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2, 6], value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5\n",
    ")\n",
    "\n",
    "# The tensor value is <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
    "tf.RaggedTensor.from_row_starts(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2, 6], row_starts=[0, 4, 4, 7, 8]\n",
    ")\n",
    "\n",
    "# The tensor value is <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
    "tf.RaggedTensor.from_row_limits(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2, 6], row_limits=[4, 4, 7, 8, 8]\n",
    ")\n",
    "\n",
    "# The tensor value is <tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>\n",
    "tf.RaggedTensor.from_uniform_row_length(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2, 6], uniform_row_length=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416f299-42fc-4325-960f-46773d5ec7a2",
   "metadata": {},
   "source": [
    "### Sparse tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ad8c1-14ad-427a-b136-566e7990f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a sparse tensor representing the following dense tensor:\n",
    "# [[1, 0, 0, 0]\n",
    "#  [0, 0, 2, 0]\n",
    "#  [0, 0, 0, 0]]\n",
    "SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0eed5-fa5b-49d5-a365-87233535a0fc",
   "metadata": {},
   "source": [
    "### Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3b4ec-7dec-4c6d-a079-dae7d6f9c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable.\n",
    "v = tf.Variable(1.)\n",
    "\n",
    "# Assign 2.0 to the variable.\n",
    "v.assign(2.)\n",
    "\n",
    "# Add 0.5 to the variable.\n",
    "v.assign_add(0.5)\n",
    "\n",
    "# Substract 0.5 from the variable.\n",
    "v.assign_sub(0.5)\n",
    "\n",
    "# Matmul a variable and a constant tensor.\n",
    "w = tf.Variable([[1.], [2.]])\n",
    "x = tf.constant([[3., 4.]])\n",
    "tf.matmul(w, x)\n",
    "\n",
    "# Variable can only be created once within a tf.function.\n",
    "class M(tf.Module):\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        if not hasattr(self, \"v\"):    # Or set self.v to None in __init__\n",
    "            self.v = tf.Variable(x)\n",
    "        return self.v * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25a213-8fdd-4e5f-be26-d49b6d8d7684",
   "metadata": {},
   "source": [
    "###  tf.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeddd2f-abef-4b82-a5f6-c3ddf8687bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset using range.\n",
    "tf.data.Dataset.range(5)                               # [0, 1, 2, 3, 4]\n",
    "tf.data.Dataset.range(2, 5)                            # [2, 3, 4]\n",
    "tf.data.Dataset.range(1, 5, 2)                         # [1, 3]\n",
    "tf.data.Dataset.range(1, 5, -2)                        # []\n",
    "tf.data.Dataset.range(5, 1)                            # []\n",
    "tf.data.Dataset.range(5, 1, -2)                        # [5, 3]\n",
    "tf.data.Dataset.range(2, 5, output_type=tf.int32)      # [2, 3, 4]\n",
    "tf.data.Dataset.range(1, 5, 2, output_type=tf.float32) # [1.0, 3.0]\n",
    "\n",
    "# Load tf data from python array\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "\n",
    "# Load dataset from txt files.\n",
    "dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])\n",
    "\n",
    "# Load data from tfrecords files.\n",
    "dataset = tf.data.TFRecordDataset([\"file1.tfrecords\", \"file2.tfrecords\"])\n",
    "\n",
    "# Create a dataset using all files matching a pattern.\n",
    "dataset = tf.data.Dataset.list_files(\"/path/*.txt\")\n",
    "\n",
    "# Split dataset into batches.\n",
    "dataset = tf.data.Dataset.range(8)\n",
    "dataset = dataset.batch(3)  # The dataset value is [[0, 1, 2], [3, 4, 5], [6, 7]]\n",
    "\n",
    "# Transform a dataset.\n",
    "dataset = dataset.map(lambda x: x*2)\n",
    "\n",
    "# Prefetch a dataset.\n",
    "dataset = tf.data.Dataset.range(3)\n",
    "dataset = dataset.prefetch(2)\n",
    "\n",
    "# Repeat a dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "dataset = dataset.repeat(3)  # [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "\n",
    "# Shuttle a dataset.\n",
    "dataset = tf.data.Dataset.range(3)\n",
    "dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
    "dataset = dataset.repeat(2)  # [1, 0, 2, 1, 0, 2]\n",
    "\n",
    "# Concat a dataset.\n",
    "a = tf.data.Dataset.range(1, 4) # [1, 2, 3]\n",
    "b = tf.data.Dataset.range(4, 8) # [4, 5, 6, 7]\n",
    "ds = a.concatenate(b)           # [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Zip two datasets.\n",
    "a = tf.data.Dataset.range(1, 4)  # [1, 2, 3]\n",
    "b = tf.data.Dataset.range(4, 7)  # [4, 5, 6]\n",
    "ds = tf.data.Dataset.zip((a, b)) # [(1, 4), (2, 5), (3, 6)]\n",
    "\n",
    "# Iterating data in tf.data.\n",
    "for element in dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38497cd8-ed85-495a-a871-6ea0cc599763",
   "metadata": {},
   "source": [
    "### tf.math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5164ed0-3d77-4548-a2ad-7ecb7cebd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute values.\n",
    "x = tf.constant([-2.25, 3.25])\n",
    "tf.abs(x) # [2.25, 3.25]\n",
    "\n",
    "# Add a scalar and a list.\n",
    "tf.add([1, 2, 3, 4, 5], 1) # [2, 3, 4, 5, 6]\n",
    "\n",
    "# Add two tensors.\n",
    "x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
    "y = tf.convert_to_tensor(1)\n",
    "z = x + y # [2, 3, 4, 5, 6]\n",
    "\n",
    "# Add a list and a tensor.\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = tf.constant([1, 2, 3, 4, 5])\n",
    "tf.add(x, y)\n",
    "\n",
    "# Add n tensors.\n",
    "a = tf.constant([[3, 5], [4, 8]])\n",
    "b = tf.constant([[1, 6], [2, 9]])\n",
    "tf.math.add_n([a, b, a]) # [[7, 16], [10, 25]]\n",
    "\n",
    "# Get the cumulative sum.\n",
    "x = tf.constant([2, 4, 6, 8])\n",
    "tf.cumsum(x) # [2, 6, 12, 20]\n",
    "\n",
    "# Get the cumulative sum for certain axis.\n",
    "y = tf.constant([[2, 4, 6, 8], [1, 3, 5, 7]])\n",
    "tf.cumsum(y, axis=0) # [[2, 4, 6, 8], [3, 7, 11, 15]]\n",
    "tf.cumsum(y, axis=1) # [[2, 6, 12, 20], [1, 4, 9, 16]]\n",
    "\n",
    "# Get the exclusive cumulative sum.\n",
    "x = tf.constant([2, 4, 6, 8])\n",
    "tf.cumsum(x, exclusive=True) # [0, 2, 6, 12]\n",
    "\n",
    "# Get the reverse cumulative sum.\n",
    "x = tf.constant([2, 4, 6, 8])\n",
    "tf.cumsum(x, reverse=True) # [18, 14, 8, 0]\n",
    "\n",
    "# Divide tensors.\n",
    "x = tf.constant([16, 12, 11])\n",
    "y = tf.constant([4, 6, 2])\n",
    "tf.divide(x, y) # [4.0, 2.0, 5.5]\n",
    "\n",
    "# Get tensor equals.\n",
    "x = tf.constant([2, 4])\n",
    "y = tf.constant(2)\n",
    "tf.math.equal(x, y) # [True, False]\n",
    "\n",
    "# Get tensor equals.\n",
    "x = tf.constant([2, 4])\n",
    "y = tf.constant([2, 4])\n",
    "tf.math.equal(x, y) # [True, True]\n",
    "\n",
    "# Multiply tensors.\n",
    "x = tf.constant(([1, 2, 3, 4]))\n",
    "tf.math.multiply(x, x) # [1, 4, 9, 16]\n",
    "\n",
    "# Multiple tensors of different shapes with broadcast.\n",
    "x = tf.ones([1, 2]);\n",
    "y = tf.ones([2, 1]);\n",
    "x * y  # [[1.0, 1.0], [1.0, 1.0]]\n",
    "\n",
    "# Compute the power of one value to another.\n",
    "x = tf.constant([[2, 2], [3, 3]])\n",
    "y = tf.constant([[8, 16], [2, 3]])\n",
    "tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
    "\n",
    "# Compute sigmoid of a tensor.\n",
    "x = tf.constant([0.0, 1.0, 50.0, 100.0])\n",
    "tf.math.sigmoid(x) # [0.5, 0.7310586, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad10a0b-3f5e-4ce2-9a28-5a96fdee832e",
   "metadata": {},
   "source": [
    "### tf.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc88db-3e62-4187-bd20-1b86c3bfd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose a matrix.\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "tf.linalg.matrix_transpose(x)  # [[1, 4], [2, 5], [3, 6]]\n",
    "\n",
    "# Matmul two tensors.\n",
    "a = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "b = tf.constant([[7, 8], [9, 10], [11, 12]])\n",
    "c = tf.matmul(a, b) # [[58, 64], [139, 154]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39550f-1264-491c-8059-751fdf893799",
   "metadata": {},
   "source": [
    "### tf.distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9cf28-ee74-4692-a977-ba966ada3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Define a mirrored strategy, and create a variable in it.\n",
    "# The variable will be mirrored on both GPU:0 and GPU:1.\n",
    "################################################################################\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
    "with strategy.scope():\n",
    "    x = tf.Variable(1.)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Variables (e.g., x in this example) created in tf.function is still mirrored.\n",
    "################################################################################\n",
    "x = []\n",
    "@tf.function  # Wrap the function with tf.function.\n",
    "def create_variable():\n",
    "    if not x:\n",
    "        x.append(tf.Variable(1.))\n",
    "    return x[0]\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
    "with strategy.scope():\n",
    "    _ = create_variable()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Dataset can also be mirrored to multiple devices within the MirroredStrategy.\n",
    "################################################################################\n",
    "my_strategy = tf.distribute.MirroredStrategy()\n",
    "with my_strategy.scope():\n",
    "  @tf.function\n",
    "  def distribute_train_epoch(dataset):\n",
    "    def replica_fn(input):\n",
    "      # process input and return result\n",
    "      return result\n",
    "\n",
    "    total_result = 0\n",
    "    for x in dataset:\n",
    "      per_replica_result = my_strategy.run(replica_fn, args=(x,))\n",
    "      total_result += my_strategy.reduce(tf.distribute.ReduceOp.SUM,\n",
    "                                         per_replica_result, axis=None)\n",
    "    return total_result\n",
    "\n",
    "  dist_dataset = my_strategy.experimental_distribute_dataset(dataset)\n",
    "  for _ in range(EPOCHS):\n",
    "    train_result = distribute_train_epoch(dist_dataset)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# MultiWorkerMirroredStrategy is used for distributed training.\n",
    "################################################################################\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(iterator):\n",
    "    def step_fn(inputs):\n",
    "        features, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(features, training=True)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    strategy.run(step_fn, args=(next(iterator),))\n",
    "\n",
    "for _ in range(NUM_STEP):\n",
    "    train_step(iterator)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Use TPUStrategy to train a model on TPUs.\n",
    "################################################################################\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Dense(2, input_shape=(5,))])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "def dataset_fn(ctx):\n",
    "    x = np.random.random((2, 5)).astype(np.float32)\n",
    "    y = np.random.randint(2, size=(2, 1))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    return dataset.repeat().batch(1, drop_remainder=True)\n",
    "\n",
    "dist_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n",
    "iterator = iter(dist_dataset)\n",
    "\n",
    "@tf.function()\n",
    "def train_step(iterator):\n",
    "    def step_fn(inputs):\n",
    "        features, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(features, training=True)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    strategy.run(step_fn, args=(next(iterator),))\n",
    "\n",
    "train_step(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a4dbd-3d9f-4d87-b6ec-4122d6a38da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3437f2d-5291-4efb-8433-aa2353200f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c8419-704d-48f1-8117-827a7849d57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6c71c-0884-4013-8e50-3dc911b78deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264393d8-127d-4a37-8096-a38ef52ee8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecca31a-c07d-4709-8a88-6cd8e9b86d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e084f4e-15b7-409c-b597-c58eb13d753e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c474f-7d83-4a6d-88a0-7f833eb44740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf40674-47ad-4b56-b422-132b6d63ef0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fae89a-8178-449b-8f00-524ddc21788c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
